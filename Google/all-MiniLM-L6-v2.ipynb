{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the Sentence Transformers model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the Parquet file\n",
    "df_pandas = pd.read_parquet(\"data/data_with_embeddings.parquet\")\n",
    "\n",
    "# Check if the embeddings are already in list format\n",
    "# If they are, no need to apply np.fromstring() again.\n",
    "# Assuming embeddings are stored as lists (float16)\n",
    "print(type(df_pandas[\"embedding\"][0]))  # Should show <class 'list'>\n",
    "\n",
    "# You can now directly use the embeddings as numpy arrays\n",
    "df_pandas[\"embedding\"] = df_pandas[\"embedding\"].apply(lambda x: np.array(x, dtype=np.float16))\n",
    "\n",
    "# Now you can use df_pandas with embeddings as numpy arrays\n",
    "print(df_pandas.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Normalize the embeddings and query for cosine similarity\n",
    "embeddings_normalized = normalize(np.array(df_pandas[\"embedding\"].tolist()).astype('float32'))\n",
    "\n",
    "# Perform a similarity search using cosine similarity\n",
    "query = \"oral\"\n",
    "query_embedding = model.encode(query).astype('float32')\n",
    "\n",
    "# Normalize query embedding\n",
    "query_normalized = normalize(query_embedding.reshape(1, -1))\n",
    "\n",
    "# Calculate cosine similarity (1 - cosine distance)\n",
    "cosine_similarities = np.dot(embeddings_normalized, query_normalized.T).flatten()\n",
    "\n",
    "k = 2  # Number of results to retrieve\n",
    "top_k_indices = cosine_similarities.argsort()[-k:][::-1]\n",
    "top_k_similarities = cosine_similarities[top_k_indices]\n",
    "\n",
    "# Display results\n",
    "for idx, sim in zip(top_k_indices, top_k_similarities):\n",
    "    print(f\"Title: {df_pandas.iloc[idx]['title']}\")\n",
    "    print(f\"Subject Codes: {df_pandas.iloc[idx]['subject_codes']}\")\n",
    "    print(f\"Cited by Count: {df_pandas.iloc[idx]['citedby_count']}\")\n",
    "    print(f\"Publisher: {df_pandas.iloc[idx]['publisher']}\")\n",
    "    print(f\"Language: {df_pandas.iloc[idx]['language']}\")\n",
    "    print(f\"Published Date: {df_pandas.iloc[idx]['published_date']}\")\n",
    "    print(f\"Authors: {df_pandas.iloc[idx]['authors']}\")\n",
    "    print(f\"Cosine Similarity: {sim:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
